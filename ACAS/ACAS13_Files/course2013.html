<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<!-- Mirrored from casid.info/ACAS13_Files/course2013.htm by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 25 Jul 2017 22:14:11 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
  <meta name="GENERATOR" content="Adobe PageMill 2.0 Mac">
  <title>Untitled Document</title></head>
<body bgcolor="#ffffff">
		<p></p>
		<p align="center"><b><font color="#187534" size="+3">Classification and Regression Trees and Forests<br>
				</font><font color="black" size="+1">December 9 &amp; 10</font></b></p>
		<p align="center">Prof. Wei-Yin Loh, Department of Statistics, University of Wisconsin, Madison<br></p>Classification
and regression trees are essential tools for data mining, machine
learning, and statistical data analysis. This year marks the 50th
anniversary of the publication of the first journal article on the
subject. In a classification or regression tree model, the data and
sample space are split into two or more partitions and a simple
statistical model is fitted to each of them. The model is intuitive to
interpret because the partitions can be displayed as a decision tree.
Besides, the models often possess prediction accuracy as good as or
better than that of linear discriminant analysis and linear regression.
This course reviews the major techniques and discusses their relative
strengths, weaknesses, capabilities, and computational requirements.
Extensions to ensemble procedures, such as bagging and random forest,
are included. Concepts are explained with examples from business,
industry, science, and engineering.<br>
<br>
Special emphasis is given to the instructor&rsquo;s GUIDE algorithm
(http://www.stat.wisc.edu/~loh/guide.html). For classification, GUIDE
can construct decision trees with nonparametric models, such as nearest
neighbor and kernel discrimination, in the nodes. For regression, GUIDE
can use least squares, least median of squares, quantile, Poisson, and
proportional hazards loss functions and apply them to univariate,
multivariate, longitudinal, and censored response data. If time
permits, instruction on the use of GUIDE and other free software will
be given. <br>
<br>
For a brief review of the subject, see Loh, W.-Y. (2011).
&ldquo;Classification and regression trees.&rdquo; Wiley
Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 1,
14-23. (http://www.stat.wisc.edu/~loh/treeprogs/guide/wires11.pdf).<br>
For a list of sample applications in the scientific literature, see http://www.stat.wisc.edu/~loh/apps.html.<br>
<br>
<a href="icas13.pdf">Course Notes</a><br>

		
		<blockquote>
  <p><i><font color="#000000">This short course is included in all conference registration plans except the one-day attendance.</font></i></p>
</blockquote>
		<p>&nbsp;</p>
<p><a href="default.html">Return to ICAS Home Page</a>
</p>
</body>
<!-- Mirrored from casid.info/ACAS13_Files/course2013.htm by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 25 Jul 2017 22:20:24 GMT -->
</html>